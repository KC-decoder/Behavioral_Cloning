The general Reinforcement Learning (RL) framework involves an agent navigating an environment, collecting observations and taking actions to maximize rewards. However, real-world scenarios often have sparse or undefined reward functions. Manually designing reward functions is difficult in complex environments. To address this, alternative methods like Behavioral Cloning, a form of Imitation Learning, can be used. By using a dataset from an expert agent, a Behavioral Cloning agent learns to imitate the expert's policy. This project aims to explore this approach using OpenAI Gym's 'Pendulum,' 'LunarLander,' and 'Car Racing' environments with a DDQN Agent's experience as a dataset. The goal is to improve the Behavioral Cloning agent's policy further through reinforcement learning.
